{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change_names.ipynb\n",
      "test\n",
      "test_HR\n",
      "test_LR\n",
      "test_SR\n",
      "test_SR_content\n",
      "train_HR\n",
      "train_LR\n",
      "train_SR\n",
      "train_SR_content\n",
      "valid_HR\n",
      "valid_LR\n",
      "valid_SR\n",
      "valid_SR_content\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to the directory you want to list\n",
    "dataset_path = './srgan_dataset'\n",
    "\n",
    "# List all files and folders in the directory\n",
    "files = os.listdir(dataset_path)\n",
    "\n",
    "# Print the list of files\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"test\"\n",
    "hr_name_path = os.path.join(dataset_path,mode+\"_HR\")\n",
    "lr_name_path = os.path.join(dataset_path,mode+\"_LR\")\n",
    "sr_name_path = os.path.join(dataset_path,mode+\"_SR\")\n",
    "image_names = list(os.listdir(hr_name_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 40\n",
    "hr_sample = Image.open(os.path.join(hr_name_path,image_names[n]))\n",
    "hr_sample = np.transpose(np.array(hr_sample,dtype=np.float64),(2,0,1))\n",
    "lr_sample = Image.open(os.path.join(lr_name_path,image_names[n]))\n",
    "lr_sample = np.transpose(np.array(lr_sample,dtype=np.float64),(2,0,1))\n",
    "sr_sample = Image.open(os.path.join(sr_name_path,image_names[n]))\n",
    "sr_sample = np.transpose(np.array(sr_sample,dtype=np.float64),(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(img1, img2):\n",
    "    # img1 and img2 have range [0, 255]\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    mse = np.mean((img1 - img2)**2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * math.log10(255.0 / math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.371847863357083 27.066042506251744\n"
     ]
    }
   ],
   "source": [
    "# print(calculate_ssim(hr_sample,lr_sample),calculate_psnr(hr_sample,lr_sample),\"   \",skimage.metrics.structural_similarity(hr_sample,lr_sample,data_range=255),skimage.metrics.peak_signal_noise_ratio(hr_sample,lr_sample,data_range=255))\n",
    "print(calculate_psnr(hr_sample,lr_sample),calculate_psnr(hr_sample,sr_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim(img1, img2):\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
    "                                                            (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    '''calculate SSIM\n",
    "    the same outputs as MATLAB's\n",
    "    img1, img2: [0, 255]\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    if img1.ndim == 2:\n",
    "        return ssim(img1, img2)\n",
    "    elif img1.ndim == 3:\n",
    "        if img1.shape[2] == 3:\n",
    "            ssims = []\n",
    "            for i in range(3):\n",
    "                ssims.append(ssim(img1, img2))\n",
    "            return np.array(ssims).mean()\n",
    "        elif img1.shape[2] == 1:\n",
    "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "    else:\n",
    "        raise ValueError('Wrong input image dimensions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(calculate_ssim(hr_sample,lr_sample),calculate_ssim(hr_sample,sr_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import torch.nn.functional as F \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution:  tensor([0.0010, 0.0076, 0.0360, 0.1094, 0.2130, 0.2660, 0.2130, 0.1094, 0.0360,\n",
      "        0.0076, 0.0010])\n",
      "Sum of Gauss Distribution: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    \"\"\"\n",
    "    Generates a list of Tensor values drawn from a gaussian distribution with standard\n",
    "    diviation = sigma and sum of all elements = 1.\n",
    "\n",
    "    Length of list = window_size\n",
    "    \"\"\"    \n",
    "    gauss =  torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "gauss_dis = gaussian(11, 1.5)\n",
    "print(\"Distribution: \", gauss_dis)\n",
    "print(\"Sum of Gauss Distribution:\", torch.sum(gauss_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of gaussian window: torch.Size([3, 1, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "def create_window(window_size, channel=1):\n",
    "\n",
    "    # Generate an 1D tensor containing values sampled from a gaussian distribution\n",
    "    _1d_window = gaussian(window_size=window_size, sigma=1.5).unsqueeze(1)\n",
    "    \n",
    "    # Converting to 2D  \n",
    "    _2d_window = _1d_window.mm(_1d_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "     \n",
    "    window = torch.Tensor(_2d_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "\n",
    "    return window\n",
    "\n",
    "window = create_window(11, 3)\n",
    "print(\"Shape of gaussian window:\", window.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim(img1, img2, val_range, window_size=11, window=None, size_average=True, full=False):\n",
    "\n",
    "    L = val_range # L is the dynamic range of the pixel values (255 for 8-bit grayscale images),\n",
    "\n",
    "    pad = window_size // 2\n",
    "    \n",
    "    try:\n",
    "        _, channels, height, width = img1.size()\n",
    "    except:\n",
    "        channels, height, width = img1.size()\n",
    "\n",
    "    # if window is not provided, init one\n",
    "    if window is None: \n",
    "        real_size = min(window_size, height, width) # window should be atleast 11x11 \n",
    "        window = create_window(real_size, channel=channels).to(img1.device)\n",
    "    \n",
    "    # calculating the mu parameter (locally) for both images using a gaussian filter \n",
    "    # calculates the luminosity params\n",
    "    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)\n",
    "    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)\n",
    "    \n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2 \n",
    "    mu12 = mu1 * mu2\n",
    "\n",
    "    # now we calculate the sigma square parameter\n",
    "    # Sigma deals with the contrast component \n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq\n",
    "    sigma12 =  F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12\n",
    "\n",
    "    # Some constants for stability \n",
    "    C1 = (0.01 ) ** 2  # NOTE: Removed L from here (ref PT implementation)\n",
    "    C2 = (0.03 ) ** 2 \n",
    "\n",
    "    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    contrast_metric = torch.mean(contrast_metric)\n",
    "\n",
    "    numerator1 = 2 * mu12 + C1  \n",
    "    numerator2 = 2 * sigma12 + C2\n",
    "    denominator1 = mu1_sq + mu2_sq + C1 \n",
    "    denominator2 = sigma1_sq + sigma2_sq + C2\n",
    "\n",
    "    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)\n",
    "\n",
    "    if size_average:\n",
    "        ret = ssim_score.mean() \n",
    "    else: \n",
    "        ret = ssim_score.mean(1).mean(1).mean(1)\n",
    "    \n",
    "    if full:\n",
    "        return ret, contrast_metric\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorify = lambda x: torch.Tensor(x.transpose((2, 0, 1))).unsqueeze(0).float().div(255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_tens = tensorify(hr_sample)\n",
    "sr_tens = tensorify(sr_sample)\n",
    "lr_tens = tensorify(lr_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9661716818809509"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim(hr_tens,lr_tens,val_range=255).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "133  out of  133  samples evaluated.\n",
      "PSNR\n",
      "SR       SRC       LR       #(SR>LR)\n",
      "22.929 25.062 32.083 38\n",
      "-----\n",
      "SSIM\n",
      "SR     SRC     LR     #(SR>LR)\n",
      "0.781 0.797 0.692 86\n",
      "\n",
      "____________\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m lr_ssim\u001b[38;5;241m.\u001b[39mappend(ssim(hr_tens,lr_tens,val_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m))\n\u001b[0;32m     36\u001b[0m sr_ssim\u001b[38;5;241m.\u001b[39mappend(ssim(hr_tens,sr_tens,val_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m255\u001b[39m))\n\u001b[1;32m---> 37\u001b[0m src_ssim\u001b[38;5;241m.\u001b[39mappend(\u001b[43mssim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhr_tens\u001b[49m\u001b[43m,\u001b[49m\u001b[43msrc_tens\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hr_sample,lr_sample,sr_sample,src_sample\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hr_tens,lr_tens,sr_tens,src_tens\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36mssim\u001b[1;34m(img1, img2, val_range, window_size, window, size_average, full)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# calculating the mu parameter (locally) for both images using a gaussian filter \u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# calculates the luminosity params\u001b[39;00m\n\u001b[0;32m     19\u001b[0m mu1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(img1, window, padding\u001b[38;5;241m=\u001b[39mpad, groups\u001b[38;5;241m=\u001b[39mchannels)\n\u001b[1;32m---> 20\u001b[0m mu2 \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m mu1_sq \u001b[38;5;241m=\u001b[39m mu1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     23\u001b[0m mu2_sq \u001b[38;5;241m=\u001b[39m mu2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modes = [\"test\",\"train\",\"valid\"]\n",
    "\n",
    "for mode in modes:\n",
    "    hr_name_path = os.path.join(dataset_path,mode+\"_HR\")\n",
    "    lr_name_path = os.path.join(dataset_path,mode+\"_LR\")\n",
    "    sr_name_path = os.path.join(dataset_path,mode+\"_SR\")\n",
    "    src_name_path = os.path.join(dataset_path,mode+\"_SR_content\")\n",
    "    image_names = list(os.listdir(hr_name_path))\n",
    "    n = len(image_names)\n",
    "    lr_psnr = []\n",
    "    sr_psnr = []\n",
    "    src_psnr = []\n",
    "    lr_ssim = []\n",
    "    sr_ssim = []\n",
    "    src_ssim = []\n",
    "\n",
    "    for i in range(n):\n",
    "        hr_sample = Image.open(os.path.join(hr_name_path,image_names[i]))\n",
    "        hr_tens = tensorify(np.array(hr_sample))\n",
    "        hr_sample = np.transpose(np.array(hr_sample,dtype=np.float64),(2,0,1))\n",
    "        lr_sample = Image.open(os.path.join(lr_name_path,image_names[i]))\n",
    "        lr_tens = tensorify(np.array(lr_sample))\n",
    "        lr_sample = np.transpose(np.array(lr_sample,dtype=np.float64),(2,0,1))\n",
    "        sr_sample = Image.open(os.path.join(sr_name_path,image_names[i]))\n",
    "        sr_tens = tensorify(np.array(sr_sample))\n",
    "        sr_sample = np.transpose(np.array(sr_sample,dtype=np.float64),(2,0,1))\n",
    "        src_sample = Image.open(os.path.join(src_name_path,image_names[i]))\n",
    "        src_tens = tensorify(np.array(src_sample))\n",
    "        src_sample = np.transpose(np.array(src_sample,dtype=np.float64),(2,0,1))\n",
    "\n",
    "\n",
    "        lr_psnr.append(calculate_psnr(hr_sample,lr_sample))\n",
    "        sr_psnr.append(calculate_psnr(hr_sample,sr_sample))\n",
    "        src_psnr.append(calculate_psnr(hr_sample,src_sample))\n",
    "        lr_ssim.append(ssim(hr_tens,lr_tens,val_range=255))\n",
    "        sr_ssim.append(ssim(hr_tens,sr_tens,val_range=255))\n",
    "        src_ssim.append(ssim(hr_tens,src_tens,val_range=255))\n",
    "\n",
    "        del hr_sample,lr_sample,sr_sample,src_sample\n",
    "        del hr_tens,lr_tens,sr_tens,src_tens\n",
    "\n",
    "    sr_psnr,lr_psnr,src_psnr = np.array(sr_psnr),np.array(lr_psnr),np.array(src_psnr)\n",
    "    sr_ssim,lr_ssim,src_ssim = np.array(sr_ssim),np.array(lr_ssim),np.array(src_ssim)\n",
    "    print(mode)\n",
    "    print(len(sr_psnr),\" out of \",n,\" samples evaluated.\")\n",
    "    print(\"PSNR\")\n",
    "    print(\"SR       SRC       LR       #(SR>LR)\")\n",
    "    print(round(sr_psnr.mean(),3),round(src_psnr.mean(),3),round(lr_psnr.mean(),3),round((sr_psnr >= lr_psnr).sum(),3))\n",
    "    print(\"-----\")\n",
    "    print(\"SSIM\")\n",
    "    print(\"SR     SRC     LR     #(SR>LR)\")\n",
    "    print(round(sr_ssim.mean(),3),round(src_ssim.mean(),3),round(lr_ssim.mean(),3),round((sr_ssim >= lr_ssim).sum(),3))\n",
    "    print(\"\\n____________\\n\")\n",
    "\n",
    "    del sr_psnr,lr_psnr,sr_ssim,lr_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
